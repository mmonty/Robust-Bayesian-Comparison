# -*- coding: utf-8 -*-
"""nonpb_betaperc.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tzHW3DfoW6-Cram6TpdX0ndJt3EmUwt0
"""

# * Copyright (c) 2022 Martin Montenegro
# * All rights reserved.
# *
# * Redistribution and use in source and binary forms, with or without
# * modification, are permitted provided that the following conditions
# * are met:
# * 1. Redistributions of source code must retain the above copyright
# *    notice, this list of conditions and the following disclaimer.
# * 2. Redistributions in binary form must reproduce the above copyright
# *    notice, this list of conditions and the following disclaimer in the
# *    documentation and/or other materials provided with the distribution.
# *
# * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR
# * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
# * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
# * IN NO EVENT SHALL THE AUTHOR OR HIS RELATIVES BE LIABLE FOR ANY DIRECT,
# * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
# * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
# * SERVICES; LOSS OF MIND, USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
# * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
# * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING
# * IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
# * THE POSSIBILITY OF SUCH DAMAGE.




from sys import prefix
import math
import numpy as np
import torch
import matplotlib as mpl
import matplotlib.pyplot as plt

device = torch.device('cuda')
#torch.set_printoptions(precision=6, sci_mode=True)

SAMPLES = 20

normal1 = torch.empty(SAMPLES).normal_(0,1)
normal2 = torch.empty(SAMPLES).normal_(2,1)

n1 = normal1.sort().values
n2 = normal2.sort().values

SIZE = 500000
BINS = SAMPLES+1
TRIALS = SAMPLES

suc = [0] * BINS

j=0
for i in range(SAMPLES):
    while j < SAMPLES and n2[j] < n1[i]:
        suc[i] += 1
        j += 1
while j < SAMPLES:
    suc[SAMPLES] += 1
    j += 1

bsuc = torch.Tensor(suc)
u = torch.zeros(SIZE)
prev = torch.zeros(SIZE)
res = torch.zeros(SIZE)

bsuc.to(device)
u.to(device)
prev.to(device)
res.to(device)


plist = torch.Tensor(np.linspace(0.01,.99,99))

nonp_unpaired = []
prev.fill_(1.0)
res.fill_(0.0)
for j in range(BINS,0,-1):
    u.uniform_().pow_(1/j)
    torch.mul(prev,u,out=prev)
    res += prev * bsuc[j-1]
b = torch.distributions.beta.Beta(res+1,TRIALS-res+1)
for p in plist:
    nonp_unpaired.append(torch.mean(b.log_prob(p).exp()).item())

nonp_paired = []
suc = 0
for i in range(SAMPLES):
    if normal2[i] > normal1[i]:
        suc += 1
b = torch.distributions.beta.Beta(suc+1,SAMPLES-suc+1)
for p in plist:
    nonp_paired.append(b.log_prob(p).exp().item())

par_unpaired = []
g1 = torch.distributions.gamma.Gamma((SAMPLES-1)/2, SAMPLES/2*torch.var(normal1,False)).sample((SIZE,))
g2 = torch.distributions.gamma.Gamma((SAMPLES-1)/2, SAMPLES/2*torch.var(normal2,False)).sample((SIZE,))
m1 = torch.normal(torch.mean(normal1), torch.sqrt(1/g1/SAMPLES))
m2 = torch.normal(torch.mean(normal2), torch.sqrt(1/g2/SAMPLES))
stat = (m2 - m1)/torch.sqrt(1/g1+1/g2)
n = torch.distributions.normal.Normal(0,1)
prop = n.cdf(stat)
for p in plist:
    b = torch.logical_and(prop > p-0.01, prop < p+0.01)
    par_unpaired.append(torch.sum(b).float().item()/SIZE)

par_paired = []
diff = normal2-normal1
g = torch.distributions.gamma.Gamma((SAMPLES-1)/2, SAMPLES/2*torch.var(diff,False)).sample((SIZE,))
m = torch.normal(torch.mean(diff), torch.sqrt(1/g/SAMPLES))
stat = m/torch.sqrt(1/g)
prop = n.cdf(stat)
for p in plist:
    b = torch.logical_and(prop > p-0.01, prop < p+0.01)
    par_paired.append(torch.sum(b).float().item()/SIZE)

m1 = max(nonp_unpaired)
m2 = max(nonp_paired)
m3 = max(par_unpaired)
m4 = max(par_paired)

maxm = max(m1,m2,m3,m4)
nonp_unpaired = [x*maxm/m1 for x in nonp_unpaired]
nonp_paired = [x*maxm/m2 for x in nonp_paired]
par_unpaired = [x*maxm/m3 for x in par_unpaired]
par_paired = [x*maxm/m4 for x in par_paired]


print(nonp_unpaired)
print(nonp_paired)
print(par_unpaired)
print(par_paired)

fig, ax = plt.subplots()

ax.plot(plist, nonp_unpaired, label = "nonp_unpaired")
#ax.plot(plist, nonp_paired, label = "nonp_paired")
ax.plot(plist, par_unpaired, label = "par_unpaired")
#ax.plot(plist, par_paired, label = "par_paired")
ax.legend()


print("hello")